{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsuspIrInE3V"
   },
   "source": [
    "# Statistical Inference\n",
    "# IFT6758 Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwybvVZjnOtN"
   },
   "source": [
    "### Classical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGNBfVmJpNP2"
   },
   "source": [
    "2. [ISLR 3.7.3] Suppose we have a dataset with five predictors, $X_1 = $ GPA, $X_2 = IQ$, $X_3 = $ Gender (1 for Female and 0 for Male), $X_4 = $ Interaction between GPA and IQ, and $X_5 = $ Interaction between GPA and Gender. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get $\\hat{\\beta}_0 = 50, \\hat{\\beta}_1 = 20, \\hat{\\beta}_2 = 0.07, \\hat{\\beta}_3 = 35, \\hat{\\beta}_4 = 0.01, \\hat{\\beta}_5 = -10$.\n",
    "\n",
    "  a. Which is correct, and why? i. For a fixed value of IQ and GPA, males earn more on average than females. ii. For a fixed value of IQ and GPA, females earn more on average than males. iii. For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough. iv. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.\n",
    "    \n",
    "  b. Predict the salary of a female with IQ of 110 and a GPA of 4.0.\n",
    "  \n",
    "  c. True or false: Since the coefficient for the GPA / IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhNdyJfDnrbY"
   },
   "source": [
    "### The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjXTVcT3wgdV"
   },
   "source": [
    "6. Suppose that $X_1, \\dots, X_n$ and $Y_1, \\dots, Y_m$ are two independent samples. As a measure of the difference in location of the two samples, the difference of the 20% trimmed means is used (each trimmed mean is the mean after discarding the 10% smallest and 10% largest values in the group). Explain how the bootstrap could be used to estimate the standard error of this difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "saNrGp6pNYNT"
   },
   "source": [
    "7. [ISLR 4.5.9] Consider the Boston housing [dataset](https://gist.githubusercontent.com/krisrs1128/2c1ce8d004b1efc18b2d6e03e84a27c6/raw/9e95c9782b46f1ede7c288466390c8f937aecc08/boston.csv).\n",
    "\n",
    "  a. Based on this dataset, provide an estimate for the population mean of `medv`. Call this estimate $\\hat{\\mu}$.\n",
    "  \n",
    "  b. Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this result. *Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.*.\n",
    "  \n",
    "  c. Now estimate the standard error $\\hat{\\mu}$ using the bootstrap. How does this compare to your answer from (b)?\n",
    "  \n",
    "  d. Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of `medv`. *Hint: You can approximate a 95% confidence interval using the formula $\\left[\\hat{\\mu} - 2 s.e.\\left(\\hat{\\mu}\\right), \\hat{\\mu} + 2 s.e.\\left(\\hat{\\mu}\\right)\\right]$.*\n",
    "  \n",
    "  e. Based on this dataset, provide an estimate $\\hat{\\mu}_{med}$ for the median value of `medv` in the population.\n",
    "  \n",
    "  f. We now would like to estimate the standard error of $\\hat{\\mu}_{med}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.\n",
    "  \n",
    "  g. Based on this dataset, provide an estimate for the 10th percentile of `medv` in Boston suburbs. Call this quantity $\\hat{\\mu}_{0.1}$.\n",
    "  \n",
    "  h. Use the bootstrap to estiamte the standard error of $\\hat{\\mu}_{0.1}$. Comment on your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ut1P7ayknsmK"
   },
   "source": [
    "### Large-Scale Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXbEMQG8v3rI"
   },
   "source": [
    "13. The data [here](https://gist.githubusercontent.com/krisrs1128/ff7b6498c89316b9dd526a0f44d92d31/raw/2683592cd4ed08d00e17d12adbc90a6bafac434c/experiments.csv) are a simulation of 1000 experiments, each seeking to detecting a difference between treatment and control. Only the last 10% of hypotheses are actually nonnull (ids 9901 to 10000).\n",
    "\n",
    "  a. For experiment, run a $t$-test comparing treatment and control, using an $\\alpha=0.05$ significance level. How many false positives (rejected hypotheses among the null IDs) do you find? What is the FDR in this instance (the fraction $\\frac{V}{R}$)?\n",
    "  \n",
    "  b. Apply a Bonferroni correction to all $p$-values. How many false positives do you find? What is the false discovery rate?\n",
    "  \n",
    "  c. Apply the Benjamini-Hochberg procedure. What is the false discovery rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x52ARUDUhJQ7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Statistical Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
